{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/skullscript/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/skullscript/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/skullscript/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/skullscript/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "stop_words = set(stopwords.words('english')) \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Document: \n",
      "Min Sentences:  1\n",
      "Max Sentences:  112\n",
      "Avg Sentences:  32.36\n",
      "Min Tokens:  16\n",
      "Max Tokens:  2305\n",
      "Avg Tokens:  633.7365\n",
      "Avg Sentence Length for Collection:  39.60853125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "\n",
    "movie_data = load_files(r\"./review_polarity/txt_sentoken\")\n",
    "x_data, y_target = movie_data.data, movie_data.target\n",
    "x, y = shuffle(x_data,y_target, random_state=0)\n",
    "\n",
    "validate_doc = []\n",
    "documents = []\n",
    "\n",
    "num_sent = []\n",
    "stemmer = WordNetLemmatizer()\n",
    "for sent in range(0, len(x)):\n",
    "    sentence = x[sent].split(b\"\\n\")\n",
    "    wa = sentence\n",
    "    length = len(sentence)\n",
    "    num_sent.append(length)\n",
    "\n",
    "print('Number of Document: ')\n",
    "print('Min Sentences: ', str(np.min(num_sent) - 1))\n",
    "print('Max Sentences: ', str(np.max(num_sent) - 1))\n",
    "print('Avg Sentences: ', str(np.mean(num_sent)- 1))\n",
    "\n",
    "#preprocessing the data getting rid of numbers special characters etc\n",
    "total_tok = 0\n",
    "num_tok = []\n",
    "collection = []\n",
    "for sent in range(0, len(x)):\n",
    "    \n",
    "    \n",
    "    #removing special character\n",
    "    sent_length = len(x[0].split(b\"\\n\"))\n",
    "    document = re.sub(r'\\W', ' ', str(x[sent]))\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    #print(sent_length)\n",
    "    document = document.split()\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    length = len(document)\n",
    "    num_tok.append(length)\n",
    "    collection_str = (length/sent_length)\n",
    "    collection.append(collection_str)\n",
    "    document = ' '.join(document)\n",
    "    #print(document)\n",
    "    documents.append(document)\n",
    "    #print(\"------------------------\\n\")\n",
    "\n",
    "\n",
    "print('Min Tokens: ',  str(np.min(num_tok)))\n",
    "print('Max Tokens: ',  str(np.max(num_tok)))\n",
    "print('Avg Tokens: ',  str(np.mean(num_tok)))\n",
    "sum_collection = 0;\n",
    "for i in range(0, len(collection)):\n",
    "    #print(collection[i])\n",
    "    sum_collection = sum_collection + collection[i]\n",
    "print('Avg Sentence Length for Collection: ', str(sum_collection/len(collection)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature size of  500\n",
      "**********Bag of Words Feature***********\n",
      "RandomForestClassifier\n",
      "avg accuracy fpr 5 fold : 0.7629411764705882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       154\n",
      "           1       0.75      0.73      0.74       146\n",
      "\n",
      "    accuracy                           0.75       300\n",
      "   macro avg       0.75      0.75      0.75       300\n",
      "weighted avg       0.75      0.75      0.75       300\n",
      "\n",
      "Validate Accuracy Score : 0.75\n",
      "\n",
      "\n",
      "MultinomialNB\n",
      "avg accuracy fpr 5 fold : 0.7641176470588235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75       154\n",
      "           1       0.73      0.73      0.73       146\n",
      "\n",
      "    accuracy                           0.74       300\n",
      "   macro avg       0.74      0.74      0.74       300\n",
      "weighted avg       0.74      0.74      0.74       300\n",
      "\n",
      "Validate Accuracy Score : 0.74\n",
      "\n",
      "\n",
      "BernoulliNB\n",
      "avg accuracy fpr 5 fold : 0.7588235294117647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77       154\n",
      "           1       0.77      0.73      0.75       146\n",
      "\n",
      "    accuracy                           0.76       300\n",
      "   macro avg       0.76      0.76      0.76       300\n",
      "weighted avg       0.76      0.76      0.76       300\n",
      "\n",
      "Validate Accuracy Score : 0.76\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "************* TFIDF Feature **************\n",
      "RandomForestClassifier\n",
      "avg accuracy fpr 5 fold : 0.7641176470588235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76       154\n",
      "           1       0.77      0.69      0.73       146\n",
      "\n",
      "    accuracy                           0.75       300\n",
      "   macro avg       0.75      0.75      0.75       300\n",
      "weighted avg       0.75      0.75      0.75       300\n",
      "\n",
      "Validate Accuracy Score : 0.7466666666666667\n",
      "\n",
      "\n",
      "MultinomialNB\n",
      "avg accuracy fpr 5 fold : 0.7658823529411765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.75       154\n",
      "           1       0.74      0.71      0.73       146\n",
      "\n",
      "    accuracy                           0.74       300\n",
      "   macro avg       0.74      0.74      0.74       300\n",
      "weighted avg       0.74      0.74      0.74       300\n",
      "\n",
      "Validate Accuracy Score : 0.74\n",
      "\n",
      "\n",
      "BernoulliNB\n",
      "avg accuracy fpr 5 fold : 0.7588235294117647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77       154\n",
      "           1       0.77      0.73      0.75       146\n",
      "\n",
      "    accuracy                           0.76       300\n",
      "   macro avg       0.76      0.76      0.76       300\n",
      "weighted avg       0.76      0.76      0.76       300\n",
      "\n",
      "Validate Accuracy Score : 0.76\n",
      "\n",
      "\n",
      "Feature size of  1000\n",
      "**********Bag of Words Feature***********\n",
      "RandomForestClassifier\n",
      "avg accuracy fpr 5 fold : 0.7794117647058824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       154\n",
      "           1       0.76      0.75      0.76       146\n",
      "\n",
      "    accuracy                           0.76       300\n",
      "   macro avg       0.76      0.76      0.76       300\n",
      "weighted avg       0.76      0.76      0.76       300\n",
      "\n",
      "Validate Accuracy Score : 0.7633333333333333\n",
      "\n",
      "\n",
      "MultinomialNB\n",
      "avg accuracy fpr 5 fold : 0.8235294117647058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76       154\n",
      "           1       0.75      0.75      0.75       146\n",
      "\n",
      "    accuracy                           0.76       300\n",
      "   macro avg       0.76      0.76      0.76       300\n",
      "weighted avg       0.76      0.76      0.76       300\n",
      "\n",
      "Validate Accuracy Score : 0.7566666666666667\n",
      "\n",
      "\n",
      "BernoulliNB\n",
      "avg accuracy fpr 5 fold : 0.7717647058823529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       154\n",
      "           1       0.76      0.76      0.76       146\n",
      "\n",
      "    accuracy                           0.77       300\n",
      "   macro avg       0.77      0.77      0.77       300\n",
      "weighted avg       0.77      0.77      0.77       300\n",
      "\n",
      "Validate Accuracy Score : 0.7666666666666667\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "************* TFIDF Feature **************\n",
      "RandomForestClassifier\n",
      "avg accuracy fpr 5 fold : 0.7788235294117647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80       154\n",
      "           1       0.79      0.76      0.78       146\n",
      "\n",
      "    accuracy                           0.79       300\n",
      "   macro avg       0.79      0.79      0.79       300\n",
      "weighted avg       0.79      0.79      0.79       300\n",
      "\n",
      "Validate Accuracy Score : 0.7866666666666666\n",
      "\n",
      "\n",
      "MultinomialNB\n",
      "avg accuracy fpr 5 fold : 0.823529411764706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       154\n",
      "           1       0.74      0.70      0.72       146\n",
      "\n",
      "    accuracy                           0.73       300\n",
      "   macro avg       0.73      0.73      0.73       300\n",
      "weighted avg       0.73      0.73      0.73       300\n",
      "\n",
      "Validate Accuracy Score : 0.7333333333333333\n",
      "\n",
      "\n",
      "BernoulliNB\n",
      "avg accuracy fpr 5 fold : 0.7717647058823529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       154\n",
      "           1       0.76      0.76      0.76       146\n",
      "\n",
      "    accuracy                           0.77       300\n",
      "   macro avg       0.77      0.77      0.77       300\n",
      "weighted avg       0.77      0.77      0.77       300\n",
      "\n",
      "Validate Accuracy Score : 0.7666666666666667\n",
      "\n",
      "\n",
      "Feature size of  1500\n",
      "**********Bag of Words Feature***********\n",
      "RandomForestClassifier\n",
      "avg accuracy fpr 5 fold : 0.8041176470588235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77       154\n",
      "           1       0.75      0.77      0.76       146\n",
      "\n",
      "    accuracy                           0.76       300\n",
      "   macro avg       0.76      0.76      0.76       300\n",
      "weighted avg       0.76      0.76      0.76       300\n",
      "\n",
      "Validate Accuracy Score : 0.7633333333333333\n",
      "\n",
      "\n",
      "MultinomialNB\n",
      "avg accuracy fpr 5 fold : 0.8123529411764705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79       154\n",
      "           1       0.78      0.77      0.78       146\n",
      "\n",
      "    accuracy                           0.78       300\n",
      "   macro avg       0.78      0.78      0.78       300\n",
      "weighted avg       0.78      0.78      0.78       300\n",
      "\n",
      "Validate Accuracy Score : 0.7833333333333333\n",
      "\n",
      "\n",
      "BernoulliNB\n",
      "avg accuracy fpr 5 fold : 0.7847058823529411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       154\n",
      "           1       0.78      0.75      0.76       146\n",
      "\n",
      "    accuracy                           0.78       300\n",
      "   macro avg       0.78      0.78      0.78       300\n",
      "weighted avg       0.78      0.78      0.78       300\n",
      "\n",
      "Validate Accuracy Score : 0.7766666666666666\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "************* TFIDF Feature **************\n",
      "RandomForestClassifier\n",
      "avg accuracy fpr 5 fold : 0.7994117647058824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79       154\n",
      "           1       0.79      0.76      0.77       146\n",
      "\n",
      "    accuracy                           0.78       300\n",
      "   macro avg       0.78      0.78      0.78       300\n",
      "weighted avg       0.78      0.78      0.78       300\n",
      "\n",
      "Validate Accuracy Score : 0.7833333333333333\n",
      "\n",
      "\n",
      "MultinomialNB\n",
      "avg accuracy fpr 5 fold : 0.8158823529411764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77       154\n",
      "           1       0.76      0.75      0.75       146\n",
      "\n",
      "    accuracy                           0.76       300\n",
      "   macro avg       0.76      0.76      0.76       300\n",
      "weighted avg       0.76      0.76      0.76       300\n",
      "\n",
      "Validate Accuracy Score : 0.76\n",
      "\n",
      "\n",
      "BernoulliNB\n",
      "avg accuracy fpr 5 fold : 0.7847058823529411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       154\n",
      "           1       0.78      0.75      0.76       146\n",
      "\n",
      "    accuracy                           0.78       300\n",
      "   macro avg       0.78      0.78      0.78       300\n",
      "weighted avg       0.78      0.78      0.78       300\n",
      "\n",
      "Validate Accuracy Score : 0.7766666666666666\n",
      "\n",
      "\n",
      "Feature size of  2000\n",
      "**********Bag of Words Feature***********\n",
      "RandomForestClassifier\n",
      "avg accuracy fpr 5 fold : 0.8011764705882353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72       154\n",
      "           1       0.71      0.75      0.73       146\n",
      "\n",
      "    accuracy                           0.73       300\n",
      "   macro avg       0.73      0.73      0.73       300\n",
      "weighted avg       0.73      0.73      0.73       300\n",
      "\n",
      "Validate Accuracy Score : 0.7266666666666667\n",
      "\n",
      "\n",
      "MultinomialNB\n",
      "avg accuracy fpr 5 fold : 0.8117647058823529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78       154\n",
      "           1       0.77      0.77      0.77       146\n",
      "\n",
      "    accuracy                           0.78       300\n",
      "   macro avg       0.78      0.78      0.78       300\n",
      "weighted avg       0.78      0.78      0.78       300\n",
      "\n",
      "Validate Accuracy Score : 0.7766666666666666\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB\n",
      "avg accuracy fpr 5 fold : 0.798235294117647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.80       154\n",
      "           1       0.80      0.74      0.77       146\n",
      "\n",
      "    accuracy                           0.78       300\n",
      "   macro avg       0.78      0.78      0.78       300\n",
      "weighted avg       0.78      0.78      0.78       300\n",
      "\n",
      "Validate Accuracy Score : 0.7833333333333333\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "************* TFIDF Feature **************\n",
      "RandomForestClassifier\n",
      "avg accuracy fpr 5 fold : 0.7858823529411764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79       154\n",
      "           1       0.79      0.75      0.77       146\n",
      "\n",
      "    accuracy                           0.78       300\n",
      "   macro avg       0.78      0.78      0.78       300\n",
      "weighted avg       0.78      0.78      0.78       300\n",
      "\n",
      "Validate Accuracy Score : 0.7833333333333333\n",
      "\n",
      "\n",
      "MultinomialNB\n",
      "avg accuracy fpr 5 fold : 0.8205882352941177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77       154\n",
      "           1       0.76      0.75      0.76       146\n",
      "\n",
      "    accuracy                           0.77       300\n",
      "   macro avg       0.77      0.77      0.77       300\n",
      "weighted avg       0.77      0.77      0.77       300\n",
      "\n",
      "Validate Accuracy Score : 0.7666666666666667\n",
      "\n",
      "\n",
      "BernoulliNB\n",
      "avg accuracy fpr 5 fold : 0.798235294117647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.80       154\n",
      "           1       0.80      0.74      0.77       146\n",
      "\n",
      "    accuracy                           0.78       300\n",
      "   macro avg       0.78      0.78      0.78       300\n",
      "weighted avg       0.78      0.78      0.78       300\n",
      "\n",
      "Validate Accuracy Score : 0.7833333333333333\n",
      "\n",
      "\n",
      "Feature size of  2500\n",
      "**********Bag of Words Feature***********\n",
      "RandomForestClassifier\n",
      "avg accuracy fpr 5 fold : 0.8129411764705882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76       154\n",
      "           1       0.74      0.80      0.77       146\n",
      "\n",
      "    accuracy                           0.77       300\n",
      "   macro avg       0.77      0.77      0.77       300\n",
      "weighted avg       0.77      0.77      0.77       300\n",
      "\n",
      "Validate Accuracy Score : 0.7666666666666667\n",
      "\n",
      "\n",
      "MultinomialNB\n",
      "avg accuracy fpr 5 fold : 0.8229411764705882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76       154\n",
      "           1       0.75      0.75      0.75       146\n",
      "\n",
      "    accuracy                           0.75       300\n",
      "   macro avg       0.75      0.75      0.75       300\n",
      "weighted avg       0.75      0.75      0.75       300\n",
      "\n",
      "Validate Accuracy Score : 0.7533333333333333\n",
      "\n",
      "\n",
      "BernoulliNB\n",
      "avg accuracy fpr 5 fold : 0.7958823529411765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       154\n",
      "           1       0.78      0.74      0.76       146\n",
      "\n",
      "    accuracy                           0.77       300\n",
      "   macro avg       0.77      0.77      0.77       300\n",
      "weighted avg       0.77      0.77      0.77       300\n",
      "\n",
      "Validate Accuracy Score : 0.77\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "************* TFIDF Feature **************\n",
      "RandomForestClassifier\n",
      "avg accuracy fpr 5 fold : 0.7805882352941177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       154\n",
      "           1       0.82      0.78      0.80       146\n",
      "\n",
      "    accuracy                           0.81       300\n",
      "   macro avg       0.81      0.81      0.81       300\n",
      "weighted avg       0.81      0.81      0.81       300\n",
      "\n",
      "Validate Accuracy Score : 0.81\n",
      "\n",
      "\n",
      "MultinomialNB\n",
      "avg accuracy fpr 5 fold : 0.8282352941176472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       154\n",
      "           1       0.74      0.72      0.73       146\n",
      "\n",
      "    accuracy                           0.74       300\n",
      "   macro avg       0.74      0.74      0.74       300\n",
      "weighted avg       0.74      0.74      0.74       300\n",
      "\n",
      "Validate Accuracy Score : 0.74\n",
      "\n",
      "\n",
      "BernoulliNB\n",
      "avg accuracy fpr 5 fold : 0.7958823529411765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       154\n",
      "           1       0.78      0.74      0.76       146\n",
      "\n",
      "    accuracy                           0.77       300\n",
      "   macro avg       0.77      0.77      0.77       300\n",
      "weighted avg       0.77      0.77      0.77       300\n",
      "\n",
      "Validate Accuracy Score : 0.77\n",
      "\n",
      "\n",
      "Feature size of  3000\n",
      "**********Bag of Words Feature***********\n",
      "RandomForestClassifier\n",
      "avg accuracy fpr 5 fold : 0.8047058823529412\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77       154\n",
      "           1       0.75      0.82      0.78       146\n",
      "\n",
      "    accuracy                           0.78       300\n",
      "   macro avg       0.78      0.78      0.78       300\n",
      "weighted avg       0.78      0.78      0.78       300\n",
      "\n",
      "Validate Accuracy Score : 0.7766666666666666\n",
      "\n",
      "\n",
      "MultinomialNB\n",
      "avg accuracy fpr 5 fold : 0.8141176470588235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77       154\n",
      "           1       0.76      0.74      0.75       146\n",
      "\n",
      "    accuracy                           0.76       300\n",
      "   macro avg       0.76      0.76      0.76       300\n",
      "weighted avg       0.76      0.76      0.76       300\n",
      "\n",
      "Validate Accuracy Score : 0.7566666666666667\n",
      "\n",
      "\n",
      "BernoulliNB\n",
      "avg accuracy fpr 5 fold : 0.7941176470588236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       154\n",
      "           1       0.79      0.73      0.76       146\n",
      "\n",
      "    accuracy                           0.78       300\n",
      "   macro avg       0.78      0.78      0.78       300\n",
      "weighted avg       0.78      0.78      0.78       300\n",
      "\n",
      "Validate Accuracy Score : 0.7766666666666666\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "************* TFIDF Feature **************\n",
      "RandomForestClassifier\n",
      "avg accuracy fpr 5 fold : 0.7988235294117647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81       154\n",
      "           1       0.82      0.75      0.78       146\n",
      "\n",
      "    accuracy                           0.80       300\n",
      "   macro avg       0.80      0.80      0.80       300\n",
      "weighted avg       0.80      0.80      0.80       300\n",
      "\n",
      "Validate Accuracy Score : 0.7966666666666666\n",
      "\n",
      "\n",
      "MultinomialNB\n",
      "avg accuracy fpr 5 fold : 0.8264705882352942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77       154\n",
      "           1       0.76      0.75      0.76       146\n",
      "\n",
      "    accuracy                           0.77       300\n",
      "   macro avg       0.77      0.77      0.77       300\n",
      "weighted avg       0.77      0.77      0.77       300\n",
      "\n",
      "Validate Accuracy Score : 0.7666666666666667\n",
      "\n",
      "\n",
      "BernoulliNB\n",
      "avg accuracy fpr 5 fold : 0.7941176470588236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       154\n",
      "           1       0.79      0.73      0.76       146\n",
      "\n",
      "    accuracy                           0.78       300\n",
      "   macro avg       0.78      0.78      0.78       300\n",
      "weighted avg       0.78      0.78      0.78       300\n",
      "\n",
      "Validate Accuracy Score : 0.7766666666666666\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100, random_state=0),\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB()\n",
    "]\n",
    "countVects = []\n",
    "tfidfVects = []\n",
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)\n",
    "\n",
    "def cross_validate(modelName, model, data, target):\n",
    "    print('\\n')\n",
    "    all_accuracies = cross_val_score(estimator=model, X= data, y=target, cv=5)\n",
    "    print(modelName)\n",
    "    print(\"All Accuracies\")\n",
    "    print(all_accuracies)\n",
    "    print(\"All Accuracies Mean\")\n",
    "    print(all_accuracies.mean())\n",
    "    print(\"Standard Deviation\")\n",
    "    print(all_accuracies.std())\n",
    "    print('\\n')\n",
    "\n",
    "def validate(models, data, target, train):\n",
    "    #vectorizer = CountVectorizer(max_features=3000, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "    #data_vect = vectorizer.fit_transform(data).toarray()\n",
    "    #y_pred = models[1].predict(data_vect)\n",
    "    #print('accuracy score: ' + str(accuracy_score(target, y_pred)))\n",
    "    \n",
    "    #vectorizer2 = CountVectorizer(max_features=2000, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "    #data_vect = vectorizer2.fit_transform(data).toarray()\n",
    "    #y_pred = models[1].predict(data_vect)\n",
    "    #print('accuracy score: ' + str(accuracy_score(target, y_pred)))\n",
    "    \n",
    "    vectorizer3 = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "    data_vect = vectorizer3.fit_transform(data).toarray()\n",
    "    y_pred = models[1].fit(data_vect)\n",
    "    y_pred = models[1].predict(data_vect)\n",
    "    print('accuracy score: ' + str(accuracy_score(target, y_pred)))\n",
    "    \n",
    "    #vectorizer4 = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "    #data_vect = vectorizer4.fit_transform(data).toarray()\n",
    "    #y_pred = models[1].predict(data_vect)\n",
    "    #print('accuracy score: ' + str(accuracy_score(target, y_pred)))\n",
    "\n",
    "def model_classification(x,y):\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "    X_train, validate_data, Y_train, validate_target = train_test_split(x,y, test_size=0.15, random_state=0)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)\n",
    "    \n",
    "    # Random Forest Algorithm is used to train our model \n",
    "    # The fit method is used to train the algorithm passing training data and training target sets\n",
    "    from sklearn.model_selection import KFold\n",
    "    folds = KFold(n_splits=5)\n",
    "    score = 0;\n",
    "    \n",
    "    \n",
    "    for model in models:\n",
    "        model_name = \"\"\n",
    "        score = 0\n",
    "        for train_index, test_index in folds.split(x_train,y_train):\n",
    "            X_train, X_test, Y_train, Y_test = x_train[train_index], x_train[test_index], \\\n",
    "                                           y_train[train_index], y_train[test_index]\n",
    "            model_name = type(model).__name__\n",
    "            model.fit(X_train, Y_train)\n",
    "            y_pred = model.predict(x_test)\n",
    "            score = score + accuracy_score(y_test, y_pred)\n",
    "        print(model_name)\n",
    "        print('avg accuracy fpr 5 fold : ' + str(score/5))\n",
    "        pred = model.predict(validate_data)\n",
    "        print(classification_report(validate_target, pred))\n",
    "        print(\"Validate Accuracy Score : \" + str(accuracy_score(validate_target, pred)))\n",
    "        print('\\n')\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "def test_diff_feature_sz():\n",
    "    sizes =[ 500, 1000, 1500, 2000, 2500, 3000 ]\n",
    "    #test_data, train_data = np.split(documents, [int(0.2*len(x))])\n",
    "    #test_target, train_target = np.split(y, [int(0.2*len(y))])\n",
    "    #print(len(test_data))\n",
    "    #print(len(train_data))\n",
    "    for sz in sizes:\n",
    "        \n",
    "        print('Feature size of ', str(sz) )\n",
    "        \n",
    "        print('**********Bag of Words Feature***********')\n",
    "        vectorizer = CountVectorizer(max_features=sz, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "        x_vect = vectorizer.fit_transform(documents).toarray()\n",
    "        #x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.15, random_state=0)\n",
    "        model_classification(x_vect,y)\n",
    "        \n",
    "        print('\\n')\n",
    "        print('************* TFIDF Feature **************')\n",
    "        tfidfconverter = TfidfVectorizer(max_features=sz, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "        x_vect2 = tfidfconverter.fit_transform(documents).toarray()\n",
    "        #x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.15, random_state=0)\n",
    "        model_classification(x_vect2,y)\n",
    "\n",
    "    #validate(models, test_data, test_target, train_data)\n",
    "\n",
    "test_diff_feature_sz()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
